{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyCBC Inference 2: Analyzing a gravitational wave\n",
    "### Collin Capano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we show how to set up a run for a gravitation wave, in this case, GW150914."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "We will need the most recent version of pycbc installed for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycbc in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages/PyCBC-867c5c-py3.6-linux-x86_64.egg (867c5c)\n",
      "Requirement already satisfied: lalsuite in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (6.69)\n",
      "Requirement already satisfied: ligo-common in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (1.18.1)\n",
      "Requirement already satisfied: Mako>=1.0.1 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (1.1.2)\n",
      "Requirement already satisfied: cython>=0.29 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (0.29.15)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (4.4.2)\n",
      "Requirement already satisfied: matplotlib>=1.5.1 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (3.1.3)\n",
      "Requirement already satisfied: pillow in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (7.0.0)\n",
      "Requirement already satisfied: h5py>=2.5 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (2.9.0)\n",
      "Requirement already satisfied: jinja2 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (2.11.1)\n",
      "Requirement already satisfied: mpld3>=0.3 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (0.3)\n",
      "Requirement already satisfied: lscsoft-glue>=1.59.3 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (2.0.0)\n",
      "Requirement already satisfied: emcee==2.2.1 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (2.2.1)\n",
      "Requirement already satisfied: requests>=1.2.1 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (2.23.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (4.8.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (1.14.0)\n",
      "Requirement already satisfied: ligo-segments in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (4.43.0)\n",
      "Requirement already satisfied: gwdatafind in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (1.0.4)\n",
      "Requirement already satisfied: astropy>=2.0.3 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (4.0)\n",
      "Requirement already satisfied: scipy>=0.16.0 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pycbc) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from lalsuite) (2.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from Mako>=1.0.1->pycbc) (1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from matplotlib>=1.5.1->pycbc) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from matplotlib>=1.5.1->pycbc) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from matplotlib>=1.5.1->pycbc) (0.10.0)\n",
      "Requirement already satisfied: pyOpenSSL in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from lscsoft-glue>=1.59.3->pycbc) (19.1.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from requests>=1.2.1->pycbc) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from requests>=1.2.1->pycbc) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from requests>=1.2.1->pycbc) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from requests>=1.2.1->pycbc) (2019.11.28)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from beautifulsoup4>=4.6.0->pycbc) (2.0)\n",
      "Requirement already satisfied: setuptools in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.1->pycbc) (45.2.0)\n",
      "Requirement already satisfied: cryptography>=2.8 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from pyOpenSSL->lscsoft-glue>=1.59.3->pycbc) (2.8)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from cryptography>=2.8->pyOpenSSL->lscsoft-glue>=1.59.3->pycbc) (1.14.0)\n",
      "Requirement already satisfied: pycparser in /work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyOpenSSL->lscsoft-glue>=1.59.3->pycbc) (2.19)\n",
      "env: PATH=/work/sumit.kumar/src/ve/python3.6/pycbc_tutorial/bin:/work/sumit.kumar/.local/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/idies/miniconda3/envs/py27/bin\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pycbc lalsuite ligo-common --no-cache-dir\n",
    "\n",
    "# This is needed to access the executables on sciserver. On a personal machine this should be ignore.\n",
    "path = %env PATH\n",
    "%env PATH=$path:/home/idies/miniconda3/envs/py27/bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBH example\n",
    "\n",
    "We will use the provided example configuration file [bbh_example.ini](bbh_example.ini). This is the configuration file you would need to analyze signals like GW150914.\n",
    "\n",
    "In the following sections, we look at the various sections of the configuration file in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "The model we will use is set by the `[model]` section. By setting the `name = gaussian_noise`, we tell `pycbc_inference` that we want to use the [GaussianNoise](https://pycbc.org/pycbc/latest/html/pycbc.inference.models.html#pycbc.inference.models.gaussian_noise.GaussianNoise) model. This means that we will be analyzing data $d$ from one or more detectors, which is sampled at some constant sample rate $1/\\Delta t$ for a period of time $T$, yielding $N = T/\\Delta t$ samples (more on how to load data below).\n",
    "\n",
    "This model assumes that the data consists of stationary Gaussian noise plus a signal $h$. The signal is modeled by a waveform model, which depends on several parameters. Which model to use is determined by the `approximant` parameter, which is set in the `static_params` section (see below).\n",
    "\n",
    "When this model is given a set of parameter values $\\vec{\\vartheta}$, it generates a frequency-domain waveform $\\tilde{h}(\\vec{\\vartheta})$ using the waveform model. It then calculates the log likelihood:\n",
    "\\begin{equation}\n",
    "\\log p(d|\\vec{\\vartheta}, h) =  -\\frac{1}{2} \\sum_i \\left< h_i(\\vec{\\vartheta}) - d_i,\\, h_i(\\vec{\\vartheta}) - d_i \\right>,\n",
    "\\end{equation}\n",
    "where the sum is over the number of detectors. The inner product is given by:\n",
    "\\begin{equation}\n",
    "\\left<a_i, \\, b_i\\right> = 4 \\Re \\sum_{k=k_0}^{N/2} \\frac{\\tilde{a}_i^{*}(k \\Delta f) \\tilde{b}_i(k \\Delta f)}{S^{(i)}_n(k\\Delta f)} \\Delta f.\n",
    "\\end{equation}\n",
    "Here, $S_n^{(i)}$ is the power spectral density of the noise in the $i$th detector and $\\Delta f = 1/T$ is the frequency resolution. This is the discrete form of the matched filter (see Matt Pitkin's talk).\n",
    "\n",
    "As we see, the model requires a lower frequency cutoff for the inner product $f_0 = k_0 \\Delta f$. This is set for each detector by setting the `{detector}-low-frequency-cutoff` option where `{detector}` is the detector name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The variable and static params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the Normal 2D example, we see that there is a `[variable_params]` section. This lists the names of all of the parameters we will be varying in the run. Now we see that there is also a `[static_params]` section. These are parameters that will be kept fixed throughout the run. In this example we have:\n",
    " * `approximant = IMRPhenomPv2`: this means that the waveform model we use will be IMRPhenomPv2\n",
    " * `f_lower = 20`: this sets the starting frequency for the waveform generation to 20Hz. *This is separate from the low frequency cutoff of the inner product, which is set in the `[model]` section.*\n",
    " * `f_ref = 20`: the \"reference\" frequency of the waveform.\n",
    "\n",
    "The `approximant` argument determines what type of waveform we will be generating. Since it is set to `IMRPhenomPv2`, we will be generating a CBC waveform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the prior\n",
    "\n",
    "**Every parameter listed in the `[variable_params]` section must have a prior specified in the file.** This is done by adding sections named `[prior-{params}]` to the file, where `{param}` is the name of the parameter that the section sets a prior for; e.g., `[prior-mass1]`. A section may provide a distribution for multiple parameters. In that case, all of the parameters must be listed in the header as a `+` separated list. For example, `[prior-ra+dec]`. The order that the parameters are provided does not matter.\n",
    "\n",
    "Each prior section must also have a `name` set. This specifies the name of the distribution to use for that parameter. Distributions are defined in PyCBC's [distributions package](https://pycbc.org/pycbc/latest/html/pycbc.distributions.html); several are available for use. For the complete list, see the table [here](https://pycbc.org/pycbc/latest/html/inference.html#configuring-the-prior).\n",
    "\n",
    "The rest of the settings in the `[prior]` sections depend on the distribution being used. For example, the `uniform` distribution requires minimum and maximum bounds to be provided for each parameter:\n",
    "```\n",
    "[prior-mass1]\n",
    "name = uniform\n",
    "min-mass1 = 10.\n",
    "max-mass1 = 80.\n",
    "```\n",
    "Some distributions require no options, since they are predefined in the code. For example, the `uniform_sky` distribution provides the appropriate distributions for right ascension and declination, which it expects to be called `ra` and `dec`, respectively. This is why that section is simply:\n",
    "```\n",
    "[prior-ra+dec]\n",
    "name = uniform_sky\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    " * The configuration file is missing a prior for the coalescene time `tc`. We know that the coalescence time of GW150914 is approximately 1126259462.42 (GPS seconds). Set a uniform prior on `tc` equal to this time $\\pm$ 0.1 s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sampler\n",
    "\n",
    "Here we are using the `emcee_pt` sampler. This is a parallel tempered sampler, so it requires a number of temperatures to be set. Note a few other differences from the analytic example here:\n",
    "  * The `burn-in-test` is set to `nacl & max_posterior`.\n",
    "  * Instead of an `niterations` option, we have `effective-nsamples = 1000`.\n",
    "  * A checkpoint interval is set: `checkpoint-interval = 2000`\n",
    "  * There is a `max-samples-per-chain` option.\n",
    "\n",
    "These are all options specific to MCMC samplers like `emcee_pt`. Details:\n",
    "\n",
    "#### The burn in option\n",
    "Multiple burn in tests may be combined using standard boolean operators like `&` and `|`. In this example, we will consider the sampler to be burned in when it has passed the `nacl` test *and* the `max_posterior` test. This means:\n",
    "\n",
    " * `nacl`: The second half of the chain must be longer than 5 times the ACL. If so, the samlper is considered burned-in at the halfway point.\n",
    " * `max_posterior`: All of the walkers must find a point that has a log posterior greater than `maxP - ndim/2`, where `maxP` is the maximum posterior value found over all the walkers and `ndim` is the number of variable parameters. The first iteration for which all the walkers pass this test is the burn in iteration.\n",
    " \n",
    "By doing `&`, we take the larger iteration of these two tests. This combination of tests has worked well for `emcee_pt`.\n",
    "\n",
    "#### Checkpointing\n",
    "When a `checkpoint-interval` is set, `pycbc_inference` will dump the results to a checkpoint file after every `checkpoint-interval` iterations. The checkpoint file has the same name as the output, but with `.checkpoint` added on to it. \n",
    "\n",
    "While ``pycbc_inference`` is running it will create a checkpoint file which\n",
    "is named ``{output-file}.checkpoint``, where ``{output-file}`` was the name\n",
    "of the file you specified with the ``--output-file`` command. If a `checkpoint-interval` is set, `pycbc_inference` will checkpoint after the given number of iterations. For `emcee_pt`, this means that it will dump the current samples to this file; when finished, the file is\n",
    "renamed to ``{output-file}``.\n",
    "\n",
    "A ``{output-file}.bkup`` is also created, which is a copy of the checkpoint file. This is kept in case the checkpoint file gets corrupted during writing. The ``.bkup`` file is deleted at the end of the run, unless ``--save-backup`` is turned on.\n",
    "\n",
    "If `pycbc_inference` is terminated while running (either by error, or by a system interrupt), the checkpoint and bkup files remain. When `pycbc_inference` is restarted, it will check for those files. If they are found, it will resume from where it last left off.\n",
    "\n",
    "#### Termination condition\n",
    "By setting `effective-nsamples` we tell the `pycbc_inference` until it has an effective number of samples greater than or equal to the specified value. Effective samples are the number of independent samples of the posterior we have. This is given by number of samples that remain after burn-in and thinned by the autocorelation time.\n",
    "\n",
    "The number of effective samples are counted at each checkpoint. For this reason, a checkpoint-interval must be provided if `effective-nsamples` is set.\n",
    "\n",
    "#### Max samples per chain\n",
    "If `max-samples-per-chain` is provided, `pycbc_inference` will ensure that no more than the given number of samples per chain are stored in the output file. Samples will be thinned on disk and in memory when a checkpoint happens to ensure this. This is important for keeping file size down. Without it, a GW run with `1000` walkers and `4` temps can result in a file that is over 100GB, since every sample will be saved. With `max-samples-per-chain = 1000`, the maximum file size is capped to ~1GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samping and waveform transforms\n",
    "You'll note a `waveform_transforms` and `sampling_transforms` sections. Those are described in more detail in the next tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data settings\n",
    "\n",
    "Options for loading the gravitational wave data are set on the command line. See [run_bbh_example.sh](run_bbh_example.sh) for details.\n",
    "\n",
    "### Challenge:\n",
    " * The data that will be analyzed is set by the `--gps-start-time` and `--gps-end-time` options. What will these be set to by the script? How much time is analyzed?\n",
    " * The longest waveform admitted by the prior is ~6s long. So why is the analyzed time longer than 6 seconds? (Hint: Recall FFT wrap around.)\n",
    " \n",
    "*Note: in a future release, data options will be moved from the command line and into the config file.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can run, we need to download frame files from [GWOSC](https://www.gw-openscience.org/about/). These contain the LIGO data that we will analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('H-H1_GWOSC_16KHZ_R1-1126257415-4096.gwf'):\n",
    "    !wget https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/H-H1_GWOSC_16KHZ_R1-1126257415-4096.gwf\n",
    "if not os.path.exists('L-L1_GWOSC_16KHZ_R1-1126257415-4096.gwf'):\n",
    "    !wget https://www.gw-openscience.org/catalog/GWTC-1-confident/data/GW150914/L-L1_GWOSC_16KHZ_R1-1126257415-4096.gwf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this example, we will just run the bash script. Running this example to completion will take several hours. Instead, we'll just run for a couple of checkpoints, kill it, then start it again to see how checkpointing works.\n",
    "\n",
    "First, do the following:\n",
    " * Set the checkpoint interval in the config file to 4.\n",
    "\n",
    "Now run the script. Watch the output. After it checkpoints (it will say \"Running sampler for 4 to 8 iterations\"), interrupt the kernel by hitting the stop button above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-03 16:05:16,906 Using seed 1897234\n",
      "2020-03-03 16:05:16,907 Running with CPU support: 1 threads\n",
      "2020-03-03 16:05:17,339 Reading configuration file\n",
      "2020-03-03 16:05:17,359 Setting up model\n",
      "2020-03-03 16:05:17,374 Setting up priors for each parameter\n",
      "2020-03-03 16:05:17,379 Sampling in mchirp, q in place of mass1, mass2\n",
      "2020-03-03 16:05:17,380 Loading waveform transforms\n",
      "2020-03-03 16:05:17,387 Determining analysis times to use\n",
      "2020-03-03 16:05:17,402 Padding H1 analysis start and end times by 4 (= psd-inverse-length/2) seconds to account for PSD wrap around effects.\n",
      "2020-03-03 16:05:17,402 Padding L1 analysis start and end times by 4 (= psd-inverse-length/2) seconds to account for PSD wrap around effects.\n",
      "2020-03-03 16:05:17,404 Reading Frames\n",
      "2020-03-03 16:06:28,752 Highpass Filtering\n",
      "2020-03-03 16:06:28,883 Converting to float64\n",
      "2020-03-03 16:06:28,899 Resampling data\n",
      "2020-03-03 16:06:29,257 Highpass Filtering\n",
      "2020-03-03 16:06:29,264 Remove Padding\n",
      "2020-03-03 16:06:29,266 Reading Frames\n",
      "2020-03-03 16:08:21,226 Highpass Filtering\n",
      "2020-03-03 16:08:21,283 Converting to float64\n",
      "2020-03-03 16:08:21,285 Resampling data\n",
      "2020-03-03 16:08:21,444 Highpass Filtering\n",
      "2020-03-03 16:08:21,450 Remove Padding\n",
      "2020-03-03 16:08:21,451 Will generate a different time series for PSD estimation\n",
      "2020-03-03 16:08:21,452 Reading Frames\n",
      "2020-03-03 16:09:33,740 Highpass Filtering\n",
      "2020-03-03 16:09:36,904 Converting to float64\n",
      "2020-03-03 16:09:39,085 Resampling data\n",
      "2020-03-03 16:09:48,476 Highpass Filtering\n",
      "2020-03-03 16:09:48,586 Remove Padding\n",
      "2020-03-03 16:09:48,588 Reading Frames\n",
      "2020-03-03 16:11:00,977 Highpass Filtering\n",
      "2020-03-03 16:11:03,658 Converting to float64\n",
      "2020-03-03 16:11:05,151 Resampling data\n",
      "2020-03-03 16:11:15,910 Highpass Filtering\n",
      "2020-03-03 16:11:16,017 Remove Padding\n",
      "2020-03-03 16:11:16,017 Applying gates to PSD data\n",
      "2020-03-03 16:11:17,044 WARNING: The following args are not being used for waveform generation: trigger_time, delta_tc\n",
      "2020-03-03 16:11:17,048 Setting up sampler\n",
      "2020-03-03 16:11:17,145 Setting max samples per chain to 1000\n",
      "2020-03-03 16:11:17,146 Looking for checkpoint file\n",
      "2020-03-03 16:11:17,146 Checkpoint not found or not valid\n",
      "2020-03-03 16:11:17,146 Creating file inference.hdf.checkpoint\n",
      "2020-03-03 16:11:21,380 Running sampler for 0 to 2000 iterations\n",
      "WARNING: leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.00 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',) [astropy.time.core]\n",
      "WARNING: leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.01 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',) [astropy.time.core]\n",
      "WARNING: leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',) [astropy.time.core]\n",
      "2020-03-03 16:11:29,540 leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.01 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',)\n",
      "WARNING: leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.04 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',) [astropy.time.core]\n",
      "WARNING: leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',) [astropy.time.core]\n",
      "2020-03-03 16:11:29,548 leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.04 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',)\n",
      "2020-03-03 16:11:29,547 leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',)\n",
      "WARNING: leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',) [astropy.time.core]\n",
      "2020-03-03 16:11:29,561 leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',)\n",
      "WARNING: leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.06 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',) [astropy.time.core]\n",
      "2020-03-03 16:11:29,564 leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.06 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',)\n",
      "WARNING: leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.03 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',) [astropy.time.core]\n",
      "2020-03-03 16:11:29,565 leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.03 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',)\n",
      "2020-03-03 16:11:29,527 leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.00 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',)\n",
      "2020-03-03 16:11:29,540 leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',)\n",
      "WARNING: leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.05 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',) [astropy.time.core]\n",
      "2020-03-03 16:11:29,564 leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.05 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',)\n",
      "WARNING: leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.04 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',) [astropy.time.core]\n",
      "2020-03-03 16:11:29,561 leap-second auto-update failed due to the following exception: RuntimeError('Cache is locked after 5.04 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.',)\n",
      "WARNING: failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067. [astropy.utils.iers.iers]\n",
      "2020-03-03 16:11:35,673 failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.\n",
      "WARNING: failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.04 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067. [astropy.utils.iers.iers]\n",
      "WARNING: failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067. [astropy.utils.iers.iers]\n",
      "2020-03-03 16:11:35,683 failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.\n",
      "2020-03-03 16:11:35,680 failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.04 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.\n",
      "WARNING: failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.03 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067. [astropy.utils.iers.iers]\n",
      "WARNING: failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.06 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067. [astropy.utils.iers.iers]\n",
      "2020-03-03 16:11:35,688 failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.06 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.\n",
      "2020-03-03 16:11:35,683 failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.03 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.\n",
      "WARNING: failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.05 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067. [astropy.utils.iers.iers]\n",
      "WARNING: failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067. [astropy.utils.iers.iers]\n",
      "2020-03-03 16:11:35,683 failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.05 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.\n",
      "2020-03-03 16:11:35,683 failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.02 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.\n",
      "WARNING: failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.01 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067. [astropy.utils.iers.iers]\n",
      "WARNING: failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.00 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067. [astropy.utils.iers.iers]\n",
      "2020-03-03 16:11:35,707 failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.00 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.\n",
      "WARNING: failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.04 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067. [astropy.utils.iers.iers]\n",
      "2020-03-03 16:11:35,708 failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.04 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.\n",
      "2020-03-03 16:11:35,697 failed to download ftp://cddis.gsfc.nasa.gov/pub/products/iers/finals2000A.all and https://datacenter.iers.org/data/9/finals2000A.all, using local IERS-B: Cache is locked after 5.01 s. This may indicate an astropy bug or that kill -9 was used. If you want to unlock the cache remove the directory /work/sumit.kumar/.astropy/cache/download/py3/lock. Lock claims to be held by process 936067.\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run `ls` to see the files in the diretory. You should see a `bbh_results.hdf.checkpoint` and `bbh_results.hdf.bkup`. These are your checkpoint and backup files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script again. Watch the messages. You should see it say that it is starting from iteration 4. Stop it after it has gotten to another checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash run_bbh_example.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace `effective-nsamples` by `niterations` in the config file to get this to complete now. Remove or comment out the `effective-nsamples` option, and replace it with: `niterations = 12`. Now re-run. You should see `pycbc_inference` start up from the last checkpoint, but stop as soon as it gets to 12 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash run_bbh_example.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the checkpoint file has been renamed to `bbh_results.hdf`, and the backup file is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we ran for such a short period of time, the samples in `bbh_results.hdf` will look nothing like the posterior. In the next tutorial, we will take a look at a completed result file which has been run for the full time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
